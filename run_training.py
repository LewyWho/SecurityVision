import os
import sys
import subprocess
import argparse
from datetime import datetime

def run_command(command, description):
    print(f"\n{'='*60}")
    print(f"–í–´–ü–û–õ–ù–ï–ù–ò–ï: {description}")
    print(f"{'='*60}")
    print(f"–ö–æ–º–∞–Ω–¥–∞: {command}")
    print(f"{'='*60}")
    
    try:
        result = subprocess.run(command, shell=True, check=True, 
                              capture_output=False, text=True)
        print(f"\n‚úÖ {description} –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ {description}: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='–ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π')
    parser.add_argument('--mode', type=str, default='quick', 
                       choices=['quick', 'full', 'compare'],
                       help='–†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--gpu', action='store_true',
                       help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)')
    parser.add_argument('--epochs', type=int, default=None,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–∂–∏–º)')
    parser.add_argument('--batch_size', type=int, default=None,
                       help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–∂–∏–º)')
    
    args = parser.parse_args()
    
    configs = {
        'quick': {
            'epochs': 10,
            'batch_size': 8,
            'models': ['yolo', 'efficientdet'],
            'description': '–ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ (10 —ç–ø–æ—Ö, 2 –º–æ–¥–µ–ª–∏)'
        },
        'full': {
            'epochs': 50,
            'batch_size': 16,
            'models': ['all'],
            'description': '–ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (50 —ç–ø–æ—Ö, –≤—Å–µ –º–æ–¥–µ–ª–∏)'
        },
        'compare': {
            'epochs': 30,
            'batch_size': 12,
            'models': ['all'],
            'description': '–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (30 —ç–ø–æ—Ö, –≤—Å–µ –º–æ–¥–µ–ª–∏)'
        }
    }
    
    config = configs[args.mode]
    
    if args.epochs:
        config['epochs'] = args.epochs
    if args.batch_size:
        config['batch_size'] = args.batch_size
    
    print(f"üöÄ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô")
    print(f"–†–µ–∂–∏–º: {args.mode}")
    print(f"–û–ø–∏—Å–∞–Ω–∏–µ: {config['description']}")
    print(f"–≠–ø–æ—Ö–∏: {config['epochs']}")
    print(f"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {config['batch_size']}")
    print(f"–ú–æ–¥–µ–ª–∏: {config['models']}")
    print(f"GPU: {'–î–∞' if args.gpu else '–ù–µ—Ç'}")
    
    if not os.path.exists('Data/train.json') or not os.path.exists('Data/test.json'):
        print("‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã Data/train.json –∏ Data/test.json —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
        return False
    
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
    try:
        import torch
        import torchvision
        import numpy as np
        import matplotlib.pyplot as plt
        import tqdm
        print("‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
    except ImportError as e:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {e}")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install -r requirements.txt")
        return False
    
    os.makedirs('models', exist_ok=True)
    os.makedirs('evaluation_results', exist_ok=True)
    os.makedirs('inference_results', exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    for model in config['models']:
        if model == 'all':
            command = f"python train.py --model all --epochs {config['epochs']} --batch_size {config['batch_size']} --lr 0.001"
        else:
            command = f"python train.py --model {model} --epochs {config['epochs']} --batch_size {config['batch_size']} --lr 0.001"
        
        success = run_command(command, f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model}")
        
        if not success:
            print(f"‚ùå –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model} –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–æ–π")
            continue
    
    print("\nüìä –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π...")
    eval_command = "python evaluate.py --evaluate_all --batch_size 16"
    eval_success = run_command(eval_command, "–û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
    
    if eval_success:
        print("\nüéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        print("\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
        print("  - models/ - –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
        print("  - evaluation_results/ - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏")
        print("  - model_comparison.json - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
        
        if os.path.exists('model_comparison.json'):
            import json
            with open('model_comparison.json', 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            if results:
                best_model = max(results, key=lambda x: x['accuracy'])
                print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model['model_name']} "
                      f"(—Ç–æ—á–Ω–æ—Å—Ç—å: {best_model['accuracy']*100:.2f}%)")
        
        print(f"\nüí° –î–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print(f"python inference.py --model_path models/[model_name]/best.pth --input [path_to_images]")
        
    else:
        print("\n‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –Ω–æ –æ—Ü–µ–Ω–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 